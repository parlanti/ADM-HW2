{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ncw00xSUdUNg"
      },
      "source": [
        "# Homework 2 - The Best Books of All Time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqGPNfapdLwz"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1jehDJndDtM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "filepath_books = \"/content/drive/MyDrive/Datasets/Datasets-ADM-HW2/lighter_books.json\"\n",
        "filepath_authors = \"/content/drive/MyDrive/Datasets/Datasets-ADM-HW2/lighter_authors.json\"\n",
        "filepath_list = \"/content/drive/MyDrive/Datasets/Datasets-ADM-HW2/list.json\"\n",
        "\n",
        "# To display all columns and not only a sample\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRk3C91ldKrC"
      },
      "outputs": [],
      "source": [
        "chunks = pd.read_json(filepath_books, lines = True, chunksize = 10000)\n",
        "\n",
        "def reset_chunks(chunksize: int = 10000) -> None:\n",
        "  global chunks\n",
        "  chunks = pd.read_json(filepath_books, lines = True, chunksize = 10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vR8SP5X20qOG"
      },
      "outputs": [],
      "source": [
        "df_authors = pd.read_json(filepath_authors, lines = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaFM1wDWd2XY"
      },
      "source": [
        "---\n",
        "# [RQ4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5r86YvWY6K2Q"
      },
      "source": [
        "1. **You should be sure there are no eponymous (different authors who have precisely the same name) in the author's dataset. Is it true?**\n",
        "\n",
        "We have to check if authors with the same name have different ids.<br>\n",
        "In our case there are 37 eponymous."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HrKrtPQ6Rxt"
      },
      "outputs": [],
      "source": [
        "# Get the columns 'id' and 'name' after counting the number of ids for each name\n",
        "count = df_authors.groupby('name')['id'].nunique()\n",
        "eponymous = count[count > 1].index\n",
        "print('There are',eponymous.size,'eponymous')\n",
        "\n",
        "## CODE to display the rows involving eponymous\n",
        "## to use the function isin() we have to convert the series into a list\n",
        "# epon_list = eponymous.astype(str).tolist()\n",
        "# df_authors.loc[df_authors.name.isin(epon_list)]#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkOQqKqyMkQB"
      },
      "source": [
        "2. **Write a function that, given a list of author_id, outputs a dictionary where each author_id is a key, and the related value is a list with the names of all the books the author has written.**\n",
        "\n",
        "We use a default dictionary to fill it while iterating and to add the dictionary keys on the fly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opb0yNk3Mjtm"
      },
      "outputs": [],
      "source": [
        "def books_from_authors(authors_ids: list) -> dict:\n",
        "  \"\"\"\n",
        "  Given a list of author_id outputs a dictionary where each author_id is\n",
        "  a key, and the related value is a list with the names of all the books the\n",
        "  author has written\n",
        "\n",
        "  Args:\n",
        "      authors_ids (list[int]): list of autor_id\n",
        "\n",
        "  Returns:\n",
        "      book_ids (dict): dictionary with author_id and book's title\n",
        "  \"\"\"\n",
        "\n",
        "  book_ids = defaultdict(list)\n",
        "\n",
        "  # For every chunk of the dataset we look for the desired titles\n",
        "  reset_chunks()\n",
        "  for chk in chunks:\n",
        "    # From each chunk we extract the records where author_id is in the list\n",
        "    # given as input\n",
        "    books = chk.loc[chk.author_id.isin(authors_ids)].reset_index()\n",
        "\n",
        "    #Then we create the desired dictionary\n",
        "    for index, row in books.iterrows():\n",
        "      book_ids[row['author_id']].append(row['title'])\n",
        "\n",
        "  return book_ids\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMHN1h-hLcGu"
      },
      "source": [
        "\n",
        "Sample query for *J.K. Rowling* (id = 1077326) and *Douglas Adams* (id = 4)\n",
        "```\n",
        "research = books_from_authors([1077326, 4])\n",
        "for key, item in research.items():\n",
        "  print(key,': ',len(item),'books (counting all the editions)')\n",
        "```\n",
        "Gives output:\n",
        "```\n",
        "1077326 :  1914 books (counting all the editions)\n",
        "4 :  1018 books (counting all the editions)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTynP21o6llJ"
      },
      "source": [
        "3. **What is the longest book title among the books of the top 20 authors regarding their average rating? Is it the longest book title overall?**\n",
        "\n",
        "The longest book title from the top 20 authors is: <br>\n",
        "\"*God's Little Flock Healed: They Will Rise on Wings Like Eagles: They Will Run and Not Get Weary; They Will Walk and Not Grow Weak. Isaiah 40:31*\"<br>\n",
        "by Stellah Mupanduki\n",
        "\n",
        "It's not the longest book title in the dataset. The maximum length for a title is 255. In the dataset there are a lot of books with such title length. We may suppose that this is a limitation of the database that truncates longer titles and adds triple dots at the end. The last script of this section shows that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrW6ar5V6oNs",
        "outputId": "62e01448-42da-4fe1-90a1-65b3f4cf98f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authors with average rating = 5: 17790\n",
            "\n",
            "\n",
            "Longest book title of the top 20 authors regarding their average rating:\n",
            "\n",
            "\tAuthor : Stellah Mupanduki\n",
            "\tTitle : God's Little Flock Healed: They Will Rise on Wings Like Eagles: They Will Run and Not Get Weary; They Will Walk and Not Grow Weak. Isaiah 40:31 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# First we have to find the top 20 authors regarding their average rating\n",
        "# Then we use the function books_from_authors() to retrieve their books and we\n",
        "# find the one with the longest title\n",
        "# TODO second part question\n",
        "\n",
        "# First of all we count the number of authors with average_rating = 5 (the maximum)\n",
        "authors_max_rating = df_authors.sort_values(by = 'average_rating', ascending = False).reset_index()[df_authors.average_rating == 5.0]\n",
        "print(\"Authors with average rating = 5:\", authors_max_rating.shape[0])\n",
        "\n",
        "# They are too much, so we decided to consider only the top 20 authors for\n",
        "# average_rating and for rating_counts\n",
        "top_20_authors = df_authors.sort_values(by = ['average_rating', 'ratings_count'], ascending = False).reset_index().loc[:20]\n",
        "\n",
        "books = books_from_authors(top_20_authors.id.astype(int).tolist())\n",
        "\n",
        "# Then we look from the longest book title among them.\n",
        "# If they are more then one then we save them all in a dictionary where\n",
        "# the key is the author_id and as values the book titles\n",
        "longest_book = defaultdict(list)\n",
        "max_title = 0\n",
        "for author_id, book_names in books.items():\n",
        "  for name in book_names:\n",
        "    if len(name) == max_title:\n",
        "      longest_book[author_id].append(name)\n",
        "    if len(name) > max_title:\n",
        "      longest_book.clear()  # clear the dictionary\n",
        "      max_title = len(name)\n",
        "      longest_book[author_id].append(name)\n",
        "\n",
        "print('\\n\\nLongest book title of the top 20 authors regarding their average rating:\\n')\n",
        "for id, names in longest_book.items():\n",
        "  # It can happen that for one author we get a list with the same title multiple\n",
        "  # times. This is due to the presence in the dataset of different editions of\n",
        "  # the same book which have the same title\n",
        "  # To avoid this we eliminate dupplicates using a set\n",
        "  names_set = set(names)\n",
        "  for name in names_set:\n",
        "    print('\\tAuthor :', top_20_authors[top_20_authors.id == id].reset_index().loc[0,'name'])\n",
        "    print('\\tTitle :',name,'\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJdFoFq77cDF",
        "outputId": "b827e5b5-aa54-431b-99c9-95d498bf3bff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Longest title length:  255 charachters\n"
          ]
        }
      ],
      "source": [
        "# Find the longest book title LENGTH in the dataset\n",
        "\n",
        "max_title = 0\n",
        "\n",
        "reset_chunks()\n",
        "for chk in chunks:\n",
        "  max_chk = chk['title'].str.len().max()\n",
        "\n",
        "  if max_chk > max_title:\n",
        "    max_title = max_chk\n",
        "\n",
        "print(\"Longest title length: \",max_title,\"charachters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsvZnM1qX1IL",
        "outputId": "cd1652de-a451-4117-c7e4-0156f1f9bbcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Title : The New England Primer Issued Prior to 1830: A Bibliographical Checklist for the More Easy Attaining the True Knowledge of This Book, Embellished with a Hundred Cuts and Now Revised, Greatly Improved and Arranged in Two Alaphabets; With Preface, Introd...\n",
            "Title length : 255 \n",
            "\n",
            "Title : A Commentary and Review of Montesquieu's Spirit of Laws, Prepared for Press from the Original Manuscript in the Hands of the Publisher (1811): To Which Are Annexed, Observations on the Thirty-First Book, by the Late M. Condorcet. and Two Letters of Hel...\n",
            "Title length : 255 \n",
            "\n",
            "Title : Ensuring Compatibility with Enhanced 911 Emergency Calling Systems: A Progress Report: Hearing Before the Subcommittee on Telecommunications and the Internet of the Committee on Energy and Commerce, House of Representatives, One Hundred Seventh Congres...\n",
            "Title length : 255 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# List the longest book titles in the first 10 chunks of the dataset\n",
        "# We can observe that the maximal length is 255 and correspondin titles are\n",
        "# truncated and finishes with triple dots\n",
        "\n",
        "longest_title = defaultdict(list)\n",
        "max_title = 0\n",
        "\n",
        "i = 0\n",
        "reset_chunks()\n",
        "for chk in chunks:\n",
        "  # From each chunk we extract the records where author_id is in the list\n",
        "  # given as input\n",
        "  books = chk.reset_index()\n",
        "\n",
        "  for index, row in books.iterrows():\n",
        "    title = row['title']\n",
        "    if len(title) == max_title:\n",
        "      longest_title[row['author_id']].append(title)\n",
        "    if len(title) > max_title:\n",
        "      longest_title.clear()  # clear the dictionary\n",
        "      max_title = len(title)\n",
        "      longest_title[row['author_id']].append(title)\n",
        "\n",
        "  if i == 9:\n",
        "    break\n",
        "  else:\n",
        "    i += 1\n",
        "\n",
        "for id, titles in longest_title.items():\n",
        "  titles_set = set(titles)\n",
        "  for title in titles_set:\n",
        "    print('Title :',title)\n",
        "    print('Title length :',len(title),'\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUVlsxp7m1WW"
      },
      "source": [
        "4. **What is the shortest overall book title in the dataset? If you find something strange, provide a comment on what happened and an alternative answer.**\n",
        "\n",
        "It does not exists a book with the shortest overall title in the dataset. Instead in the database there are many book whose title consists in only one charachter.<br>\n",
        "In our research we also found out that there are books without a title. We counted them (33 books) and we decided to consider them as anomalies and to avoid them.<br>\n",
        "\n",
        "The first script looks for the 5 shortest book titles in the first chunk of the dataset (books with multiple editions are considered only once). Since we found a lot of book titles consisting in only one alphanumeric charater, we decided to write a new script to count the books whose title length is 1 (avoiding the books where the author is \"NOT A BOOK\").<br><br>\n",
        "The books whose title consists in only one charachter are 652.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "5zoubrTH_8tZ",
        "outputId": "fc982523-f536-4038-ac2f-556b160f1d00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 33 books with an empty title\n",
            "Here a sapmle of books with empty title: \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c47dcbd2-9dc2-4863-b045-44d130c130eb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author_name</th>\n",
              "      <th>author_id</th>\n",
              "      <th>work_id</th>\n",
              "      <th>isbn</th>\n",
              "      <th>isbn13</th>\n",
              "      <th>asin</th>\n",
              "      <th>language</th>\n",
              "      <th>average_rating</th>\n",
              "      <th>rating_dist</th>\n",
              "      <th>ratings_count</th>\n",
              "      <th>text_reviews_count</th>\n",
              "      <th>publication_date</th>\n",
              "      <th>original_publication_date</th>\n",
              "      <th>format</th>\n",
              "      <th>edition_information</th>\n",
              "      <th>image_url</th>\n",
              "      <th>publisher</th>\n",
              "      <th>num_pages</th>\n",
              "      <th>series_id</th>\n",
              "      <th>series_name</th>\n",
              "      <th>series_position</th>\n",
              "      <th>shelves</th>\n",
              "      <th>description</th>\n",
              "      <th>authors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1995819</th>\n",
              "      <td>7857246</td>\n",
              "      <td></td>\n",
              "      <td>Jacques André Naigeon</td>\n",
              "      <td>3418710</td>\n",
              "      <td>10995532</td>\n",
              "      <td></td>\n",
              "      <td>2940009438689</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0.00</td>\n",
              "      <td>5:0|4:0|3:0|2:0|1:0|total:0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>https://s.gr-assets.com/assets/nophoto/book/11...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2046459</th>\n",
              "      <td>8065192</td>\n",
              "      <td></td>\n",
              "      <td>Paul Scarron</td>\n",
              "      <td>670347</td>\n",
              "      <td>12755867</td>\n",
              "      <td></td>\n",
              "      <td>2940010082123</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0.00</td>\n",
              "      <td>5:0|4:0|3:0|2:0|1:0|total:0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>https://s.gr-assets.com/assets/nophoto/book/11...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2052149</th>\n",
              "      <td>8086737</td>\n",
              "      <td></td>\n",
              "      <td>Joseph Ennemoser</td>\n",
              "      <td>581668</td>\n",
              "      <td>12822154</td>\n",
              "      <td></td>\n",
              "      <td>2940010001957</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0.00</td>\n",
              "      <td>5:0|4:0|3:0|2:0|1:0|total:0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>https://s.gr-assets.com/assets/nophoto/book/11...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2173750</th>\n",
              "      <td>8569155</td>\n",
              "      <td></td>\n",
              "      <td>Johann Jakob Hess</td>\n",
              "      <td>3299662</td>\n",
              "      <td>13437816</td>\n",
              "      <td></td>\n",
              "      <td>2940005095763</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0.00</td>\n",
              "      <td>5:0|4:0|3:0|2:0|1:0|total:0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>https://s.gr-assets.com/assets/nophoto/book/11...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2455300</th>\n",
              "      <td>9827732</td>\n",
              "      <td></td>\n",
              "      <td>Aesop</td>\n",
              "      <td>12452</td>\n",
              "      <td>868263</td>\n",
              "      <td></td>\n",
              "      <td>2940017505991</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>4.05</td>\n",
              "      <td>5:43293|4:40553|3:25752|2:4400|1:1082|total:11...</td>\n",
              "      <td>115080</td>\n",
              "      <td>2068</td>\n",
              "      <td></td>\n",
              "      <td>-560</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>https://s.gr-assets.com/assets/nophoto/book/11...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[{'name': 'to-read', 'count': 49457}, {'name':...</td>\n",
              "      <td></td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c47dcbd2-9dc2-4863-b045-44d130c130eb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c47dcbd2-9dc2-4863-b045-44d130c130eb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c47dcbd2-9dc2-4863-b045-44d130c130eb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4dbdb76c-744d-42e3-8b31-54c65b847a16\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4dbdb76c-744d-42e3-8b31-54c65b847a16')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4dbdb76c-744d-42e3-8b31-54c65b847a16 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "              id title            author_name  author_id   work_id isbn  \\\n",
              "1995819  7857246        Jacques André Naigeon    3418710  10995532        \n",
              "2046459  8065192                 Paul Scarron     670347  12755867        \n",
              "2052149  8086737             Joseph Ennemoser     581668  12822154        \n",
              "2173750  8569155            Johann Jakob Hess    3299662  13437816        \n",
              "2455300  9827732                        Aesop      12452    868263        \n",
              "\n",
              "                isbn13 asin language  average_rating  \\\n",
              "1995819  2940009438689                          0.00   \n",
              "2046459  2940010082123                          0.00   \n",
              "2052149  2940010001957                          0.00   \n",
              "2173750  2940005095763                          0.00   \n",
              "2455300  2940017505991                          4.05   \n",
              "\n",
              "                                               rating_dist  ratings_count  \\\n",
              "1995819                        5:0|4:0|3:0|2:0|1:0|total:0              0   \n",
              "2046459                        5:0|4:0|3:0|2:0|1:0|total:0              0   \n",
              "2052149                        5:0|4:0|3:0|2:0|1:0|total:0              0   \n",
              "2173750                        5:0|4:0|3:0|2:0|1:0|total:0              0   \n",
              "2455300  5:43293|4:40553|3:25752|2:4400|1:1082|total:11...         115080   \n",
              "\n",
              "         text_reviews_count publication_date original_publication_date format  \\\n",
              "1995819                   0                                                     \n",
              "2046459                   0                                                     \n",
              "2052149                   0                                                     \n",
              "2173750                   0                                                     \n",
              "2455300                2068                                       -560          \n",
              "\n",
              "        edition_information  \\\n",
              "1995819                       \n",
              "2046459                       \n",
              "2052149                       \n",
              "2173750                       \n",
              "2455300                       \n",
              "\n",
              "                                                 image_url publisher  \\\n",
              "1995819  https://s.gr-assets.com/assets/nophoto/book/11...             \n",
              "2046459  https://s.gr-assets.com/assets/nophoto/book/11...             \n",
              "2052149  https://s.gr-assets.com/assets/nophoto/book/11...             \n",
              "2173750  https://s.gr-assets.com/assets/nophoto/book/11...             \n",
              "2455300  https://s.gr-assets.com/assets/nophoto/book/11...             \n",
              "\n",
              "        num_pages series_id series_name series_position  \\\n",
              "1995819                                                   \n",
              "2046459                                                   \n",
              "2052149                                                   \n",
              "2173750                                                   \n",
              "2455300                                                   \n",
              "\n",
              "                                                   shelves description authors  \n",
              "1995819                                                 []                None  \n",
              "2046459                                                 []                None  \n",
              "2052149                                                 []                None  \n",
              "2173750                                                 []                None  \n",
              "2455300  [{'name': 'to-read', 'count': 49457}, {'name':...                None  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the number of books whose title is an empty string\n",
        "\n",
        "empty_titles = pd.DataFrame()\n",
        "\n",
        "reset_chunks()\n",
        "for chk in chunks:\n",
        "  tmp = chk[chk['title'].str.strip() == '']\n",
        "  if tmp.shape[0] > 0:\n",
        "    empty_titles = pd.concat([empty_titles, tmp])\n",
        "\n",
        "print(\"There are\", empty_titles.shape[0],\"books with an empty title\")\n",
        "print(\"Here a sapmle of books with empty title: \")\n",
        "empty_titles.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "h1mcUVQqnCqo",
        "outputId": "1f17b362-442c-414a-86e9-a0e722ace735"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The 5 shortest book titles:\n",
            "Title  : a\n",
            "Title  : G\n",
            "Title  : Q\n",
            "Title  : π\n",
            "Title  : 4\n"
          ]
        }
      ],
      "source": [
        " # Find the 5 SHORTEST book title LENGTH in the first chunk\n",
        "\n",
        "shortest_titles = list()\n",
        "\n",
        "reset_chunks(200000)\n",
        "for chk in chunks:\n",
        "  min_5_lengths = chk['title'].str.len().nsmallest(5).tolist()\n",
        "  min_5_titles = chk[chk['title'].str.len().isin(min_5_lengths) & (chk['author_name']!='NOT A BOOK')]\n",
        "  titles_list = min_5_titles[['title','author_name']].drop_duplicates(ignore_index=True)['title'].tolist()\n",
        "  shortest_titles = shortest_titles + titles_list\n",
        "  shortest_titles = sorted(shortest_titles, key = lambda x: len(x))\n",
        "  shortest_titles = shortest_titles[0:min(5, len(shortest_titles))]\n",
        "  break\n",
        "\n",
        "print(\"The 5 shortest book titles:\")\n",
        "for title in shortest_titles:\n",
        "  print('Title  :',title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gsxi5dIAyhTe"
      },
      "outputs": [],
      "source": [
        "# Find the book titles constisting in only one charachter\n",
        "\n",
        "shortest_titles = pd.DataFrame()\n",
        "\n",
        "reset_chunks()\n",
        "for chk in chunks:\n",
        "  min_titles = chk[(chk['title'].str.len() == 1) & (chk['author_name']!='NOT A BOOK')]\n",
        "  shortest_titles = pd.concat([shortest_titles, min_titles])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rp5RZZQ3dOs",
        "outputId": "e06d1ab5-996f-4317-894f-c3ba1c3be914"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of books with titles consisting in only 1 charachter: 652\n"
          ]
        }
      ],
      "source": [
        "print('Number of books with titles consisting in only 1 charachter:',shortest_titles.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek15f5_Kd6e6"
      },
      "source": [
        "---\n",
        "# [RQ7]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHCn1ks4gdad"
      },
      "source": [
        "1. **Estimate the probability that a book has over 30% of the ratings above 4.**\n",
        "\n",
        "The result is 52.02%.\n",
        "\n",
        "In our analysis we saw that the records that are not books do not contain the number of pages, or contain an empty string. We have also dropped the record with 'author_name' = 'NOT A BOOK'. The last that we did is to consider only the books whose 'rating_dist' is well formatted.\n",
        "\n",
        "Since the rating distribution is discrete, i.e. can assume only integer values from 1 to 5 included, our probability coincides with the *probability that a book has over 30% of the ratings equals to 5*.\n",
        "\n",
        "For every chunk of the data we choosed to use vectorization using the apply method. This allowed us to lower the execution time of the script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4FMqjkpghtp",
        "outputId": "247c0505-b240-4337-ed08-cc1b2588cc2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The probability that a book has over 30% of ratings above 4 is:  52.02\n"
          ]
        }
      ],
      "source": [
        "# First of all one should check that the total is correct. Should we do that?\n",
        "# Alsi check that the total is the same as rating_counts?\n",
        "\n",
        "# Check if is a book looking at num_pages (apart from format)\n",
        "\n",
        "def parse_ratings(ratings: str) -> dict:\n",
        "  \"\"\"\n",
        "  This funcion parses a string like '5:1674064|4:664833|3:231195|2:41699|1:16215|total:2628006'\n",
        "  and returns a dictionary where the keys are '1','2','3','4','5','total' and the values are the\n",
        "  corresponding rating counts\n",
        "  \"\"\"\n",
        "  result = dict()\n",
        "  # We check if the string is correctly formatted. Otherwise we return an\n",
        "  # empty dictionary\n",
        "  if re.match(r'^(\\d+:\\d+\\|)*total:\\d+$', ratings):\n",
        "    ratings = ratings.split(\"|\")\n",
        "    for item in ratings:\n",
        "      index, value = item.split(\":\")\n",
        "      result[index] = int(value)\n",
        "\n",
        "  return result\n",
        "\n",
        "num_books_above_30 = 0\n",
        "num_total_books = 0\n",
        "\n",
        "reset_chunks()\n",
        "for chk in chunks:\n",
        "  tmp = chk[(chk.ratings_count > 0) & (chk.num_pages.notna()) & (chk.num_pages.str.strip() != '') & (chk.author_name != 'NOT A BOOK')][[\"id\", \"rating_dist\"]]\n",
        "\n",
        "  # Parse the string 'rating_dist' and transform it into a dictionary\n",
        "  # We will add a new column to the temporary DataFrame\n",
        "  tmp['rating_dict'] = tmp['rating_dist'].apply(parse_ratings)\n",
        "\n",
        "  # Remove the records where the rating_dist field is empty or the total of the ratings is 0\n",
        "  tmp = tmp[tmp['rating_dict'].apply(lambda x: (x != '') and 'total' in x and x['total'] > 0)]\n",
        "\n",
        "  # Add the columns we will use later to compute the desired probability\n",
        "  tmp['percentage_above_4'] = tmp.apply(lambda row: row['rating_dict']['5'] / row['rating_dict']['total'], axis = 1)\n",
        "  tmp['rating_total'] = tmp.apply(lambda row: row['rating_dict']['total'], axis = 1)\n",
        "\n",
        "  # Now we can use our data to update the variables we use to compute the probability.\n",
        "  # Update the total books number (this is necessary because we have\n",
        "  # filtered the rows that do not contain a book)\n",
        "  num_total_books += tmp.shape[0]\n",
        "  num_books_above_30 += tmp[tmp.percentage_above_4 >= 0.3].shape[0]\n",
        "\n",
        "prob = num_books_above_30 / num_total_books * 100\n",
        "print(f\"The probability that a book has over 30% of ratings above 4 is: {prob: .2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvgN90BTNL8a"
      },
      "source": [
        "2. **Estimate the probability that an author publishes a new book within two years from its last work.**\n",
        "\n",
        "To compute this probability we want to evaluate the ratio\n",
        "\n",
        "$$\\frac{\\sum_{\\text{author}}\\text{\\# of intervals} \\neq 0 \\text{ of books published within two years by that author }}{\\sum_{\\text{author}}\\text{\\# of intervals} \\neq 0 \\text{ among consecutive publications by that author}}$$\n",
        "<br>\n",
        "\n",
        "We assume that a book must have a number of pages that is neither NaN or an empty string. In this way we try to not consider records with 'format' like 'Audio CDs' or 'MP3'.\n",
        "\n",
        "For the same reason we consider only those books whose 'original_publication_date' is not empty and does not raise an error while trying to convert it to a DateTime format. We found that some date are negative and we decided to not consider those records.\n",
        "\n",
        "Our strategy begins with, once retrieved the useful attributes, ordering the DataFrame by 'author_id' and 'original_publication_date'. Then we compute all the date differences by consecutive publications of the same author.\n",
        "We choosed remove the records with time difference = 0 because:\n",
        "* we are interested in intervals\n",
        "* we do not consider the authors that have published only one book\n",
        "\n",
        "At this point we can count the books that have pubblication date difference within two years (730 days) and the total number of date differences among consecutive publications.\n",
        "\n",
        "\n",
        "The probability that an author publishes a new book within two years from its last work is 20.87%.\n",
        "\n",
        "In the end we choose to write a function that, given an author_id, calculates the probability that he/her publishes a new book within two years. In return 0 also for authors that have published only one book."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXrLtS_Njq7S"
      },
      "outputs": [],
      "source": [
        "# First of all we filter the books dataset and we consider only the\n",
        "# columns that we need\n",
        "\n",
        "books = pd.DataFrame()\n",
        "\n",
        "reset_chunks()\n",
        "for chk in chunks:\n",
        "  # Consider only the records with valid num_pages and original_pubblication_date that is not empty\n",
        "  tmp = chk[(chk.num_pages.notna()) & (chk.num_pages.str.strip() != '') & (chk.original_publication_date.str.strip() != '')][['id','author_id','original_publication_date']]\n",
        "  books = pd.concat([books, tmp], ignore_index = True)\n",
        "\n",
        "# We find the ids of books with original_publication_date that is not convertible to DateTime\n",
        "incorrect_dates = books[pd.to_datetime(books['original_publication_date'], errors='coerce').isna()]\n",
        "incorrect_dates_id = incorrect_dates['id'].tolist()\n",
        "\n",
        "# Drop incorrect records from our dataframe\n",
        "books = books[~books['id'].isin(incorrect_dates_id)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEMP1x91qaKD",
        "outputId": "bcaf452e-6cf9-4801-82dd-57403bd4f742"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of books published withintwo years:  788498\n",
            "The probability that an author publishes a new book within two years from its last work:  20.87 %\n"
          ]
        }
      ],
      "source": [
        "# Now we can convert the date to a correct DateTime format\n",
        "# Records with only the year are set by default month=January and day=01\n",
        "books['original_publication_date'] = pd.to_datetime(books['original_publication_date'])\n",
        "\n",
        "# We order the dataframe by author_id and original_publication_date\n",
        "books = books.sort_values(by = ['author_id','original_publication_date'], ascending = True)\n",
        "\n",
        "# Here we calculate all the differences between two consecutive publications\n",
        "# of each single author, using a function and apply()\n",
        "def calculate_intervals(grouped_by_author):\n",
        "    return grouped_by_author['original_publication_date'].diff()\n",
        "\n",
        "# Apply the custom function to each author group\n",
        "books['pub_date_interval'] = books.groupby('author_id').apply(calculate_intervals).reset_index(level = 0, drop = True)\n",
        "\n",
        "total = books.shape[0]\n",
        "\n",
        "# Now we remove the books where pub_date_interval = 0. This is done for a correct\n",
        "# computation of the probability. We remove books published in the same day.\n",
        "# In this way also remove the authors that have published only one book\n",
        "# (and so they cannot have published two books within two years).\n",
        "books = books[books['pub_date_interval'] > pd.Timedelta(days=0)]\n",
        "\n",
        "# Now we get, grouped by author, the number of books that have been published within two years\n",
        "# We remove the entries where the interval is zero, which corresponds to publications in the same day,\n",
        "# that we assume to be impossible\n",
        "\n",
        "books_within_2years = books[books['pub_date_interval'] <= pd.Timedelta(days=730)]\n",
        "\n",
        "# Evaluate the desired probability\n",
        "prob = books_within_2years.shape[0] / total  * 100\n",
        "\n",
        "print(\"The number of books published within two years: \", books_within_2years.shape[0])\n",
        "print(\"The probability that an author publishes a new book within two years from its last work: \", round(prob, 2),\"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAUgk3697EMQ"
      },
      "outputs": [],
      "source": [
        "def prob_within_2years(author_id: int) -> float:\n",
        "  \"\"\"\n",
        "  Given an author_id, calculates the probability that he/her publishes a\n",
        "  new book within two years. In return 0 also for authors that have published\n",
        "  only one book.\n",
        "  \"\"\"\n",
        "  books = pd.DataFrame()\n",
        "\n",
        "  reset_chunks()\n",
        "  for chk in chunks:\n",
        "    # Consider only the records with valid num_pages and original_pubblication_date that is not empty\n",
        "    tmp = chk[(chk.num_pages.notna()) & (chk.num_pages.str.strip() != '') & (chk.original_publication_date.str.strip() != '') & (chk.author_id == author_id)][['id','author_id','original_publication_date']]\n",
        "    books = pd.concat([books, tmp], ignore_index = True)\n",
        "\n",
        "  # We find the ids of books with original_publication_date that is not convertible to DateTime\n",
        "  incorrect_dates = books[pd.to_datetime(books['original_publication_date'], errors='coerce').isna()]\n",
        "  incorrect_dates_id = incorrect_dates['id'].tolist()\n",
        "\n",
        "  # Drop incorrect records from our dataframe\n",
        "  books = books[~books['id'].isin(incorrect_dates_id)]\n",
        "\n",
        "  if books.shape[0] == 0: return 0\n",
        "\n",
        "  # Now we can convert the date to a correct DateTime format\n",
        "  # Records with only the year are set by default month=January and day=01\n",
        "  books['original_publication_date'] = pd.to_datetime(books['original_publication_date'])\n",
        "\n",
        "  # We order the dataframe by author_id and original_publication_date\n",
        "  books = books.sort_values(by = ['author_id','original_publication_date'], ascending = True)\n",
        "\n",
        "  # Here we calculate all the differences between two consecutive publications\n",
        "  books['pub_date_interval'] = books['original_publication_date'].diff().reset_index(level = 0, drop = True)\n",
        "\n",
        "  total = books.shape[0]\n",
        "\n",
        "  books = books[books['pub_date_interval'] > pd.Timedelta(days=0)]\n",
        "\n",
        "  if books.shape[0] == 0: return 0\n",
        "\n",
        "  books_within_2years = books[books['pub_date_interval'] <= pd.Timedelta(days=730)]\n",
        "\n",
        "  # Evaluate the desired probability\n",
        "  prob = books_within_2years.shape[0] / total  * 100\n",
        "\n",
        "  return prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73XvrJ01-6Ks",
        "outputId": "75d74624-b2bd-473d-f057-774212ecb0d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The probability that Douglas Adams publishes a new book within two years from its last work is:  3.61%\n"
          ]
        }
      ],
      "source": [
        "# For example we test the function prob_within_2years() with\n",
        "# 'Douglas Adams' that has author_id = 4 (he's dead, but in the database there\n",
        "# is no information about it)\n",
        "douglas_prob = prob_within_2years(4)\n",
        "print('The probability that Douglas Adams publishes a new book within two years from its last work is: ', round(douglas_prob, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-3dJlYNNP_L"
      },
      "source": [
        "3. **In the file list.json, you will find a peculiar list named \"The Worst Books of All Time.\" Estimate the probability of a book being included in this list, knowing it has more than 700 pages.**\n",
        "\n",
        "To evaluate this probability we have to use the conditional probability. In other word:\n",
        "\n",
        "$$\\mathbb{P}(\\text{a book is in 'The Worst Books of All Time'} | \\text{the book has more than 700 pages}) =\\\\ =  \\frac{\\text{joint probability}}{\\text{marginal probability}}$$\n",
        "<br> where\n",
        "$$\\text{joint probability} = \\mathbb{P}(\\text{a book is in 'The Worst Books of All Time'}\\cap \\text{the book has more than 700 pages})$$\n",
        "<br>and\n",
        "$$\\text{marginal probability} = \\mathbb{P}(\\text{a book has more than 700 pages})$$\n",
        "\n",
        "The derired probability is 0.002%. <br>This means that among the books with more than 700 pages, only 1 out of 50000 is in 'The Worst Books of All TIme' list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQkpnXmo9ZkK",
        "outputId": "fb461f49-1de9-4275-aa0b-e42619b77076"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of books in 'The Worst Books of All Time' list: 7393\n"
          ]
        }
      ],
      "source": [
        "# First of all we retrive the books inside 'The Worst Books of All Time'\n",
        "# It is the first record (the one with id == 2) inside the 'list.json' dataset\n",
        "\n",
        "worst_book_record = pd.Series(dtype = object)\n",
        "\n",
        "list_chunks = pd.read_json(filepath_list, lines = True, chunksize = 10)\n",
        "for chk in list_chunks:\n",
        "  worst_books_record = chk.loc[0]\n",
        "  break\n",
        "\n",
        "# List containing the worst books' ids\n",
        "books_json = worst_books_record['books']\n",
        "print(\"Number of books in 'The Worst Books of All Time' list:\", len(books_json))\n",
        "\n",
        "# Creating a list with all the book ids as integer\n",
        "worst_book_ids = [int(item['book_id']) for item in books_json]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6oD6GXbNUAR",
        "outputId": "1b151750-7f6d-431d-a0d2-4b770f195bd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The joint probability is: 0.006%\n",
            "The marginal probability is: 2.81%\n",
            "\n",
            "The probability of a book being included in this list, knowing it has more than 700 pages, is: 0.002%\n"
          ]
        }
      ],
      "source": [
        "# Now we look into the books daatset and we save a DataFrame with 'id' and\n",
        "# 'num_pages' of the worst books\n",
        "worst_books = pd.DataFrame(columns = ['id','num_pages'])\n",
        "\n",
        "pages_list = list()\n",
        "\n",
        "reset_chunks()\n",
        "for chk in chunks:\n",
        "  tmp = chk[chk['id'].astype(int).isin(worst_book_ids)][['id','num_pages']]\n",
        "  worst_books = pd.concat([worst_books, tmp])\n",
        "\n",
        "  # We also save the number of pages for all books, to evaluate the probability.\n",
        "  # We do not consider the books with empty number of pages\n",
        "  pages_list += chk[chk['num_pages'].str.strip() != '']['num_pages'].tolist()\n",
        "\n",
        "\n",
        "# The probability that a book is in the Worst Books List AND has more than 700 pages.\n",
        "# First of all we remove records with invalid num_pages\n",
        "worst_books = worst_books[worst_books['num_pages'].astype(str).str.strip() != '']\n",
        "num_worst_moreThan700 = worst_books[worst_books['num_pages'].astype(int) > 700].shape[0]\n",
        "prob_intersection = num_worst_moreThan700 / len(pages_list) * 100\n",
        "\n",
        "print(f'The joint probability is: {round(prob_intersection,3)}%')\n",
        "\n",
        "# The probability that a books has more than 700 pages\n",
        "num_moreThan700 = len([x for x in pages_list if x > 700])\n",
        "prob_moreThan700 = num_moreThan700 / len(pages_list) * 100\n",
        "\n",
        "print(f'The marginal probability is: {round(prob_moreThan700,2)}%')\n",
        "\n",
        "print(f'\\nThe probability of a book being included in this list, knowing it has more than 700 pages, is: {round(prob_intersection / prob_moreThan700, 4 )}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO3eD_yxNUyF"
      },
      "source": [
        "4. **Are the events X=’Being Included in The Worst Books of All Time list’ and Y=’Having more than 700 pages’ independent? Explain how you have obtained your answer.**\n",
        "\n",
        "From the probability theory we know that the two events are independent if and only if\n",
        "\n",
        "$$\\mathbb{P}(X \\cap Y) = \\mathbb{P}(X)\\mathbb{P}(Y)$$\n",
        "\n",
        "We have that:\n",
        "*   $\\mathbb{P}(X) \\approx 0.187 $\n",
        "*   $\\mathbb{P}(Y) \\approx 2.81 $\n",
        "*   $\\mathbb{P}(X \\cap Y) \\approx  0.00556$\n",
        "*   $\\mathbb{P}(X)\\mathbb{P}(Y) \\approx  0.525$\n",
        "\n",
        "Since $\\mathbb{P}(X \\cap Y) \\neq \\mathbb{P}(X)\\mathbb{P}(Y)$ we found that $X$ and $Y$ are not independent.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCj1PUDfkSFR",
        "outputId": "8517cdfe-aa93-4a2c-f16e-129933ec39c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "P(X) =  0.18689977\n",
            "P(Y) =  2.80918476\n",
            "\n",
            "P(X)P(Y) =  0.525036\n",
            "P(X intersection Y) =  0.00556174\n"
          ]
        }
      ],
      "source": [
        "prob_x = len(worst_book_ids) / len(pages_list) * 100\n",
        "print('P(X) = ',round(prob_x, 8))\n",
        "print('P(Y) = ',round(prob_moreThan700, 8))\n",
        "print('\\nP(X)P(Y) = ',round(prob_x*prob_moreThan700, 8))\n",
        "print('P(X intersection Y) = ',round(prob_intersection, 8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmF-Z195_9aY"
      },
      "source": [
        "---\n",
        "# [CLQ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYRoS0lBr8CD"
      },
      "source": [
        "Our script __`commandline_original.sh`__ contains:\n",
        "\n",
        "```\n",
        "#!/bin/bash\n",
        "jq -c '. | {id: (.id), title: (.title), total_books_count: (.works | map(.books_count | tonumber) | add)}' series.json >> sum.json\n",
        "jq -c -s 'sort_by(.total_books_count) | reverse[]' sum.json >> ordered.json\n",
        "sed -n '1,5p' ordered.json | jq .\n",
        "rm sum.json ordered.json\n",
        "\n",
        "```\n",
        "The first line is not part of the script, but instruct the operating system to use the specified interpreter. In this case it's the common shell.<br>\n",
        "We use the bash command jq to parse the `series.json` file and to filter it.\n",
        "\n",
        "\n",
        "The second line does the following operations:\n",
        "1. from the `series.json` file outputs a json formatted text where each object has the following keys: '**id**', '**title**', '**total_books_count**'. The first two keys are the same of the original serie object, while the third is computed in the following way. For each works does the following:\n",
        "> * first of all we use the map function to convert the '**books_count**' values to numbers (because the `series.json` file provides strings)  \n",
        "> * then we add all the '**book_counts**' of the same work\n",
        "> * we save the result of the addition into the field '**total_books_count**'\n",
        "2. save the text formatted as json into a temporary file called `sum.json`\n",
        "\n",
        "The third line parses the file `sum.json` and does the following operations:\n",
        "> * sort the json objects with regard to the field '**total_books_count**'\n",
        "> * reverse the sorted object (because the default sorting is in ascending order)\n",
        "> * output the result in a temporary file named `ordered.json`\n",
        "\n",
        "The fourth line prints to the screen (formated as json) the first 5 objects of the file `ordered.json` (which are the top 5 series with the highest total '**books_count**' among all of their associated books). More specifically we are printing the first 5 lines of that file, where each line is a single object.\n",
        "\n",
        "The last lines delete the temporary files `sum.json` and `ordered.json`.\n",
        "\n",
        "\n",
        "\\\\\n",
        "Then we tried to get a more robust script implementation from ChatGPT. Our __commandline_LLM.sh__ script contains the following two lines:\n",
        "\n",
        "```\n",
        "#!/bin/bash\n",
        "cat series.json | jq -c '. | {id: .id, title: .title, total_books_count: (.works | map(.books_count | tonumber) | add)}' | jq -s 'sort_by(-.total_books_count) | .[:5]'\n",
        "```\n",
        "We obtained it with the following three queries:\n",
        "1. *The file series.json contains a list of book series. In each series's 'works' field there is a list of books that are part of that series, each book has a field 'books_count' . For each work sum the 'books_count'. Report the the top 5 series with the highest total 'books_count' among all of their associated books. The output should be a list of the five json objects with fields 'id','title','total_books_count'. Use command line tools*<br>\n",
        "As result we received\n",
        "```\n",
        "cat series.json | jq -c '.[] | {id: .id, title: .title, total_books_count: (.works | map(.books_count) | add)}' | jq -s 'sort_by(-.total_books_count) | .[:5]'\n",
        "```\n",
        "We manually changed `jq -c '.[]` with `jq -c '.` in order to let jq reading correctly all objects.\n",
        "2. since we got an error we queried again the LLM with the error: *jq: error (at <stdin>:226659): string (\"117826822\") cannot be negated* and the LLM printed the final script.\n",
        "\n",
        "\n",
        "Both the result and the LLM script are correct. We claim it's correctness by comparing it with our original script. They do the same thing but with different filters. The ChatGPT script is, without any doubt, faster then our because avoids to write temporary files to the disk. This operation would be very slow. The addition part is the same as in our script. Then it sorts the 'total_books_count' in descending order by simply adding a minus sign as prefix. In the end it prints to the screen the result in a more efficient way, which is by simply considering the first five sorted objects.\n",
        "\n",
        "\n",
        "We compared the execution time of the two scripts on the same local Ubuntu machine:\n",
        "> * __`commandline_original.sh`__ : ~20 seconds\n",
        "> * __`commandline_LLM.sh`__ : ~17 seconds\n",
        "\n",
        "Below are the output of the two scripts:\n",
        "\n",
        "![Our script](images/CLQ_original.png)\n",
        "![LLM script](images/CLQ_LLM.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EFu-CkLAOsh"
      },
      "source": [
        "---\n",
        "# [Bonus 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHnBUymQATwn"
      },
      "source": [
        "1. *Select one alternative library to Pandas (i.e., Dask, Polar, Vaex, Datatable, etc.), upload authors.json dataset, and filter authors with at least 100 reviews. Do the same using Pandas and compare performance in terms of milliseconds.*\n",
        "\n",
        "We chose to used Dask.\n",
        "\n",
        "From the following script we had the following results:\n",
        "* the execution time for Pandas is: `20254 ms`\n",
        "* the execution time for Dask is:   `40743 ms`\n",
        "\n",
        "This is interesting because we know that Dask is faster. But in this case it is slower because the dataset is smaller than the memory size. Pandas is optimized for that and takes less time to execute it.\n",
        "\n",
        "On the other hand, if we have to process datasets whose dimension is bigger than the available memory then Dask is faster. Moreover, Dask can be executed on a cluster of server to increase the speed of the task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9N5-KFuMdtB",
        "outputId": "9a355dd5-3027-4e2c-d9ae-14a4972a510c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authors with at least 100 reviews:  64565\n",
            "Dask performance (in milliseconds):  40743\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import dask.dataframe as dd\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Load the dataset with Dask\n",
        "ddf_authors = dd.read_json(filepath_authors, lines = True)\n",
        "\n",
        "ddf_filtered = ddf_authors[ddf_authors.text_reviews_count >= 100]\n",
        "\n",
        "authors_more_100_reviews = ddf_filtered.shape[0].compute()\n",
        "\n",
        "exec_time = time.time() - start_time\n",
        "print('Authors with at least 100 reviews: ', authors_more_100_reviews)\n",
        "print('Dask performance (in milliseconds): ', round(exec_time * 1000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYOeugN6Dqkp",
        "outputId": "4b85db05-8f8b-4970-cd41-2df01b312b5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authors with at least 100 reviews:  64565\n",
            "Pandas performance (in milliseconds):  20254\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Load the dataset with Pandas\n",
        "df_authors = pd.read_json(filepath_authors, lines = True)\n",
        "\n",
        "df_filtered = pd.DataFrame()\n",
        "\n",
        "df_filtered = df_authors[df_authors.text_reviews_count >= 100]\n",
        "\n",
        "authors_more_100_reviews = df_filtered.shape[0]\n",
        "\n",
        "exec_time = time.time() - start_time\n",
        "print('Authors with at least 100 reviews: ', authors_more_100_reviews)\n",
        "print('Pandas performance (in milliseconds): ', round(exec_time * 1000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxfEb_r6QuFh"
      },
      "source": [
        "2. **Select one alternative library to Pandas (i.e., Dask, Polar, Vaex, Datatable, etc.), upload books.json, and join them with authors.json based on author_id. How many books don’t have a match for the author?**\n",
        "\n",
        "For this question we used the library *PySpark*.\n",
        "\n",
        "We tried to use Dask but we where not able to find out a solution for the exception: \"*ValueError: The columns in the computed data do not match the columns in the provided metadata\n",
        "Order of columns does not match dask*\"\n",
        "\n",
        "We found out that there no books without a match for the author."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auSgW3UTxYpo",
        "outputId": "e2050fc9-fba0-4ae9-a596-3aa7a5c64eed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of books without a match for the author is:  0\n"
          ]
        }
      ],
      "source": [
        "!pip install -q pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"BonusQuestion\").getOrCreate()\n",
        "\n",
        "# Load the two datasets\n",
        "sparkdf_books = spark.read.json(filepath_books)\n",
        "sparkdf_authors = spark.read.json(filepath_authors)\n",
        "\n",
        "# We rename the 'id' column to 'author_id' in order to be able\n",
        "# to join the two datasets\n",
        "sparkdf_authors = sparkdf_authors.withColumnRenamed('id', 'author_id')\n",
        "\n",
        "sparkdf_joined = sparkdf_books.join(sparkdf_authors, \"author_id\", \"inner\")\n",
        "\n",
        "# Now we can count the number of rows we are interested in\n",
        "num_books = sparkdf_books.count()\n",
        "num_books_match = sparkdf_joined.count()\n",
        "\n",
        "# Calculate the number of unmatched books\n",
        "num_books_no_match = num_books - num_books_match\n",
        "\n",
        "print(\"The number of books without a match for the author is: \", num_books_no_match)\n",
        "\n",
        "# Release the resources occupied the pyspark session\n",
        "spark.stop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nAYBmQ-Pu5R"
      },
      "source": [
        "---\n",
        "# [Bonus 2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpVAv3ODWDRR"
      },
      "source": [
        "We chose to mine the author dataset.\n",
        "\n",
        "First of all we queried ChatGPT for a list of literary genres and, for each genre, a list of the most common words associated to that genre.\n",
        "\n",
        "For the authors we looked for the literary genre inside the 'about' field. We created a DataFrame where the indexes are the author ids and the columns the literary genres. That we filled this DataFrame simply counting how many times each genre name appears inside the 'about' field.\n",
        "\n",
        "Then we wrote a function that, given an author id, gives as output the genre name (or a list if more than one) of the most common genre (or genres) used to describe the author.\n",
        "\n",
        "In the end we add a column to the original author DataFrame called 'literary_genre', that contains a list with the associated genre names.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qx9o1ot5UAz4"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Dictionary obtained using ChatGPT of the most common words used\n",
        "# for the most common literary genres\n",
        "literature_genres_dict = {\n",
        "    \"Fiction\": [\"Protagonist\", \"Plot\", \"Character\", \"Setting\", \"Conflict\", \"Theme\"],\n",
        "    \"Mystery\": [\"Detective\", \"Clue\", \"Suspense\", \"Alibi\", \"Whodunit\", \"Red Herring\"],\n",
        "    \"Science Fiction\": [\"Futuristic\", \"Technology\", \"Aliens\", \"Spaceship\", \"Dystopian\", \"Speculative\"],\n",
        "    \"Fantasy\": [\"Magic\", \"Mythical\", \"Dragons\", \"Wizards\", \"Quest\", \"Enchantment\"],\n",
        "    \"Romance\": [\"Love\", \"Relationship\", \"Passion\", \"Heartbreak\", \"Chemistry\", \"Affection\"],\n",
        "    \"Historical Fiction\": [\"Era\", \"Historical\", \"Authenticity\", \"Period\", \"Setting\", \"Anachronism\"],\n",
        "    \"Adventure\": [\"Quest\", \"Exploration\", \"Adrenaline\", \"Hero\", \"Challenge\", \"Journey\"],\n",
        "    \"Horror\": [\"Fear\", \"Terror\", \"Suspense\", \"Supernatural\", \"Haunting\", \"Nightmare\"],\n",
        "    \"Drama\": [\"Conflict\", \"Tension\", \"Emotion\", \"Tragedy\", \"Dialogue\", \"Intensity\"],\n",
        "    \"Poetry\": [\"Metaphor\", \"Rhyme\", \"Stanza\", \"Imagery\", \"Verses\", \"Rhythm\"],\n",
        "    \"Comedy\": [\"Humor\", \"Laughter\", \"Satire\", \"Wit\", \"Parody\", \"Irony\"],\n",
        "    \"Biography\": [\"Life\", \"Autobiography\", \"Memoir\", \"Achievements\", \"Personal\", \"Influence\"]\n",
        "}\n",
        "\n",
        "# Creating a list only for literature genres\n",
        "literature_genres = [x.lower() for x in literature_genres_dict.keys()] + ['novel']\n",
        "\n",
        "all_words = [word.lower() for key, lst in literature_genres_dict.items() for word in lst]\n",
        "all_words.sort()\n",
        "all_words = list(set(all_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kJm9LRKTtqr"
      },
      "outputs": [],
      "source": [
        "# Loading the dataset and saving the authors 'id' and 'about' columns in an other\n",
        "# DataFrame for a faster computation\n",
        "df_authors = pd.read_json(filepath_authors, lines = True)\n",
        "df_authors_about = df_authors[['id','about']]\n",
        "\n",
        "# Then we use the bag-of-words representation on the 'about' column, saving only\n",
        "# the words in the pre-defined list 'literature_genres'\n",
        "bag_words_authors = pd.DataFrame(columns = literature_genres, index = df_authors_about.id)\n",
        "# Set all entries to zero\n",
        "bag_words_authors[bag_words_authors.isna()] = 0\n",
        "\n",
        "\n",
        "def get_vector(description: str) -> Counter:\n",
        "  \"\"\"\n",
        "  This function takes as input a string with the description of an author and\n",
        "  counts how many time the literature_genres word appear in the description.\n",
        "  The output is a Counter.\n",
        "  \"\"\"\n",
        "  # Remove punctuation with a regex\n",
        "  description = re.sub(r'[^\\w\\s]', '', description)\n",
        "  description = description.lower()\n",
        "  words = description.split()\n",
        "\n",
        "  # Create the Counter\n",
        "  word_counter = Counter(word for word in words if word in literature_genres)\n",
        "\n",
        "  return word_counter\n",
        "\n",
        "def fill_matrix(row) -> None:\n",
        "  \"\"\"\n",
        "  This matrix fills the DataFrame bag_words_authors with the occurrence\n",
        "  of the genre names\n",
        "  \"\"\"\n",
        "  counter = get_vector(row['about'])\n",
        "\n",
        "  if len(counter) != 0:\n",
        "    tmp = pd.Series(0, index=literature_genres)\n",
        "    tmp.update(counter)\n",
        "    bag_words_authors.loc[row['id']] = tmp\n",
        "\n",
        "# We use the apply function to improve the computation speed\n",
        "df_authors_about.apply(fill_matrix, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cSTJfvCf27E",
        "outputId": "ca58d502-151d-43d0-913d-b0e1a4d105f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The percentage of authors that match at least one word: 29.55%\n"
          ]
        }
      ],
      "source": [
        "# Here we evaluate the percentage of descriptions that match at least one\n",
        "# genre of the list 'literature_genres'\n",
        "num_not_null = bag_words_authors[bag_words_authors.sum(axis = 1) != 0].shape[0]\n",
        "percentage_not_null = num_not_null / bag_words_authors.shape[0] * 100\n",
        "print(f\"The percentage of authors that match at least one word: {round(percentage_not_null,2)}%\")\n",
        "\n",
        "# We drop all the records with no match\n",
        "bag_words = bag_words_authors.drop(labels = bag_words_authors[bag_words_authors.sum(axis = 1) == 0].index, axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiFSzYFC9lij"
      },
      "outputs": [],
      "source": [
        "def get_genre(author_id: int) -> list:\n",
        "  \"\"\"\n",
        "  This function takes as input the id of an author and returns a list\n",
        "  with the genre that we associate to it.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    row = bag_words.loc[author_id]\n",
        "  except KeyError:\n",
        "    return []\n",
        "\n",
        "  maximum = max(row)\n",
        "  indices_maximum = np.where(row == maximum)[0]\n",
        "  return [x for x in bag_words.columns[indices_maximum]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOgU6JApbhxk",
        "outputId": "dd2b000a-f910-4e74-a895-f1fa1fa4bc74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Literary genres associated to J.K. Rowling: ['fantasy']\n"
          ]
        }
      ],
      "source": [
        "# Here is an example where we ask for the literary genre of J.K. Rowling\n",
        "# whose author id is 1077326\n",
        "\n",
        "test_id = 1077326\n",
        "genres = get_genre(test_id)\n",
        "if len(genres) == 0:\n",
        "  print(f\"Unfortunately we have no idea for {df_authors[df_authors['id'] == test_id]['name'].tolist()[0]}\")\n",
        "else:\n",
        "  print(f\"Literary genres associated to {df_authors[df_authors['id'] == test_id]['name'].tolist()[0]}: {genres}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "OCWas10VUbZI",
        "outputId": "df921b33-e03b-4606-984a-f5a7616efd26"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9b9fdd5f-94ea-49a4-91a6-42f8388e7f53\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ratings_count</th>\n",
              "      <th>average_rating</th>\n",
              "      <th>text_reviews_count</th>\n",
              "      <th>work_ids</th>\n",
              "      <th>book_ids</th>\n",
              "      <th>works_count</th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>gender</th>\n",
              "      <th>image_url</th>\n",
              "      <th>about</th>\n",
              "      <th>fans_count</th>\n",
              "      <th>literary_genre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2862064</td>\n",
              "      <td>4.19</td>\n",
              "      <td>62681</td>\n",
              "      <td>[3078186, 135328, 1877624, 74123, 3078120, 104...</td>\n",
              "      <td>[386162, 13, 8695, 8694, 6091075, 365, 569429,...</td>\n",
              "      <td>106</td>\n",
              "      <td>4</td>\n",
              "      <td>Douglas Adams</td>\n",
              "      <td>male</td>\n",
              "      <td>https://images.gr-assets.com/authors/159137433...</td>\n",
              "      <td>Douglas Noël Adams was an English author, comi...</td>\n",
              "      <td>19826</td>\n",
              "      <td>[novel]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1417316</td>\n",
              "      <td>4.02</td>\n",
              "      <td>84176</td>\n",
              "      <td>[613469, 2305997, 940892, 2611786, 7800569, 31...</td>\n",
              "      <td>[9791, 21, 28, 24, 7507825, 27, 10538, 25, 26,...</td>\n",
              "      <td>75</td>\n",
              "      <td>7</td>\n",
              "      <td>Bill Bryson</td>\n",
              "      <td>male</td>\n",
              "      <td>https://images.gr-assets.com/authors/157859752...</td>\n",
              "      <td>William McGuire \"Bill\" Bryson, OBE, FRS was bo...</td>\n",
              "      <td>16144</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>56159</td>\n",
              "      <td>4.53</td>\n",
              "      <td>352</td>\n",
              "      <td>[17150, 808427, 20487307, 90550, 25460625, 171...</td>\n",
              "      <td>[349254, 15222, 14833682, 15221, 18126815, 152...</td>\n",
              "      <td>14</td>\n",
              "      <td>10</td>\n",
              "      <td>Jude Fisher</td>\n",
              "      <td>female</td>\n",
              "      <td>https://images.gr-assets.com/authors/141145711...</td>\n",
              "      <td>Jude Fisher is the pseudonym for &lt;a href=\"http...</td>\n",
              "      <td>60</td>\n",
              "      <td>[fiction, fantasy, novel]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b9fdd5f-94ea-49a4-91a6-42f8388e7f53')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9b9fdd5f-94ea-49a4-91a6-42f8388e7f53 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9b9fdd5f-94ea-49a4-91a6-42f8388e7f53');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-401c9111-5019-4415-b854-37c7633dee19\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-401c9111-5019-4415-b854-37c7633dee19')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-401c9111-5019-4415-b854-37c7633dee19 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   ratings_count  average_rating  text_reviews_count  \\\n",
              "0        2862064            4.19               62681   \n",
              "1        1417316            4.02               84176   \n",
              "2          56159            4.53                 352   \n",
              "\n",
              "                                            work_ids  \\\n",
              "0  [3078186, 135328, 1877624, 74123, 3078120, 104...   \n",
              "1  [613469, 2305997, 940892, 2611786, 7800569, 31...   \n",
              "2  [17150, 808427, 20487307, 90550, 25460625, 171...   \n",
              "\n",
              "                                            book_ids  works_count  id  \\\n",
              "0  [386162, 13, 8695, 8694, 6091075, 365, 569429,...          106   4   \n",
              "1  [9791, 21, 28, 24, 7507825, 27, 10538, 25, 26,...           75   7   \n",
              "2  [349254, 15222, 14833682, 15221, 18126815, 152...           14  10   \n",
              "\n",
              "            name  gender                                          image_url  \\\n",
              "0  Douglas Adams    male  https://images.gr-assets.com/authors/159137433...   \n",
              "1    Bill Bryson    male  https://images.gr-assets.com/authors/157859752...   \n",
              "2    Jude Fisher  female  https://images.gr-assets.com/authors/141145711...   \n",
              "\n",
              "                                               about  fans_count  \\\n",
              "0  Douglas Noël Adams was an English author, comi...       19826   \n",
              "1  William McGuire \"Bill\" Bryson, OBE, FRS was bo...       16144   \n",
              "2  Jude Fisher is the pseudonym for <a href=\"http...          60   \n",
              "\n",
              "              literary_genre  \n",
              "0                    [novel]  \n",
              "1                         []  \n",
              "2  [fiction, fantasy, novel]  "
            ]
          },
          "execution_count": 172,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add the literary genres to each author in a new column named 'literary_genre'\n",
        "\n",
        "df_authors['literary_genre'] = df_authors.apply(lambda author: get_genre(author['id']), axis = 1)\n",
        "df_authors.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9qByWbQf0B4"
      },
      "source": [
        "---\n",
        "# [AWSQ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cirxKJnL_xYv"
      },
      "source": [
        "The answer to this research question requires to create an AWS EC2 instance. We decided to launch an instance with the following characteristics:\n",
        "\n",
        "> * Amazon Machine Image:\n",
        "`Ubuntu Server 22.04 LTS (HVM), SSD Volume Type, Architecture 64-bit (x86)`\n",
        "\n",
        "> * Instance type: `t2.large (2 vCPU, 8 GiB Memory)`\n",
        "\n",
        "> * Network settings: `Allow SSH traffic from anywhere (0.0.0.0/0)`\n",
        "\n",
        "> * Storage: `20 GiB of gp2 (General Purpose SSD)`\n",
        "\n",
        "\n",
        "In order to connect to the instance we enter the same directory where we downloaded the ssh key. Then then we open a terminal and run the following commands:\n",
        "\n",
        "```\n",
        "sudo chmod 400 \"mykeypair.pem\"\n",
        "ssh -i \"mykeypair.pem\" ubuntu@ec2-52-0-31-203.compute-1.amazonaws.com\n",
        "```\n",
        "\n",
        "Now the SSH connection is open and we can work on the machine using the CLI.\n",
        "\n",
        "First of all we have to update the software and to download the AWS CLI package:\n",
        "```\n",
        "sudo apt update && sudo apt upgrade\n",
        "sudo apt install awscli\n",
        "```\n",
        "The EC2 instance still does not have pip and the python modules that we need to run the script, so we install them:\n",
        "```\n",
        "sudo apt install python3-pip\n",
        "pip install pandas\n",
        "```\n",
        "\n",
        "Then we upload the 'list.json' file and the 'awsq.py' script (that provides the 5 most commonly used tags for book lists):\n",
        "```\n",
        "scp -i mykeypair.pem list.json ubuntu@ec2-52-0-31-203.compute-1.amazonaws.com:/home/ubuntu/\n",
        "scp -i mykeypair.pem awsq.py ubuntu@ec2-52-0-31-203.compute-1.amazonaws.com:/home/ubuntu/\n",
        "```\n",
        "\n",
        "In the end we run the script with the following command:\n",
        "```\n",
        "python3 awsq.py\n",
        "```\n",
        "\n",
        "The outcome of the script is the following.\n",
        "The top 5 most frequently used tags are:\n",
        "\n",
        "| tag | # usage |\n",
        "|:---:|:---:|\n",
        "|\tromance          |  6001 times|\n",
        "|\tfiction          |  5291 times|\n",
        "| young-adult      |  5016 times|\n",
        "|\tfantasy          |  3666 times|\n",
        "|\tscience-fiction  |  2779 times|\n",
        "\n",
        "The script also outputs the execution time. The two execution times are:\n",
        "\n",
        "| systems | time |\n",
        "|:---:|:---:|\n",
        "|\tlocal ubuntu machine  |  69 seconds|\n",
        "|\tEC2 instance\t      |  31 seconds|\n",
        "\n",
        "\n",
        "We can see that the AWS EC2 instance is twice as fast as our local system.\n",
        "\n",
        "Below is the python script 'awsq.py' used to compare the two systems:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liVxqJEdJP70"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import json\n",
        "from collections import Counter\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "chunks = pd.read_json(\"list.json\", lines = True, chunksize = 100)\n",
        "\n",
        "tag_counter = Counter()\n",
        "\n",
        "for chk in chunks:\n",
        "    tag_lists = chk['tags'].tolist()\n",
        "\n",
        "    # tag_list is a list of lists, so we have to concatenate them.\n",
        "    # We had to put an if statement in the list comprehension because\n",
        "    # some items are not lists but float64 variables\n",
        "    tag_list = [item.lower() for lst in tag_lists for item in (lst if hasattr(lst, '__iter__') else str(lst))]\n",
        "\n",
        "    tag_counter.update(tag_list)\n",
        "\n",
        "print(\"The top 5 most frequently used tags are:\\n\")\n",
        "for elem in tag_counter.most_common(5):\n",
        "    print(f\"\\t{elem[0]: <15}  :  {elem[1]} times\")\n",
        "\n",
        "execution_time = time.time() - start_time\n",
        "print(f\"\\nExecution time: {round(execution_time)} seconds\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
